\chapter{Introdução}

A performance artística musical, quando praticada em conjunto, requer alto nível de colaboração entre os participantes. Em música, sobretudo gêneros com tendências improvisacionais como \textit{jazz}, \textit{blues} e \textit{rock}, o ato de ouvir e reagir ao som de seus companheiros é tão importante quanto aquele produzido individualmente. Dessa forma, o \textit{feedback} auditivo de baixa latência dos instrumentos tocados é fundamental para que haja uma sensação fluida entre os participantes.

Normalmente, músicos performando em conjunto em um mesmo ambiente físico raramente possuem problemas relacionados à latência. No entanto, em um contexto de distanciamento social, encorajado durante à Pandemia de COVID-19, músicos ao redor do mundo viram-se obrigados a transferirem esse ambiente para um virtual \textit{online}. Além dos \textit{delays} causados pelas conversões de sinais analógicos para digitais e vice-versa e do tempo de escrita no \textit{buffer} em memória \cite{how_low_can_you_go}, a latência apresentada pela transmissão de pacotes pela Internet apresenta-se como um dos maiores desafios para sobrepor, onde, a depender de fatores como distância entre os músicos e velocidade da rede, pode ser o maior gargalo do processo de \textit{streaming} de áudio.

Aplicações comuns de videoconferências, como \textit{Zoom}, \textit{Google Meet} e \textit{FaceTime}, que oferecem plataformas para conversações em tempo real, também possuem baixa tolerância a latência, permitindo no máximo 150 ms para manter uma conversa inteligível \cite{cisco} - limite atingível em velocidades medianas de conexões. No entanto, no contexto da prática musical, o limite é ainda menor, variando entre 10 ms e 55 ms \cite{mcphearson}, demonstrando que tais aplicações não podem ser utilizadas para esse propósito. 

Para lidar com esse problema, \textit{softwares} voltados especificamente para a colaboração musical \textit{online} apresentam uma variedade de abordagens diferentes. \textit{LoLa} \cite{lola}, \textit{SoundJack} \cite{soundjack} e \textit{JamKazam} \cite{jamkazam}, por exemplo, implementam otimizações na camada de rede - como conectar clientes diretamente entre si via \textit{P2P} (\textit{peer-to-peer}) - oferecendo latências razoáveis entre distâncias medianas. Outras aplicações, como o \textit{Jammr} \cite{jammr} e \textit{JamTaba} \cite{jamtaba}, dispensam o requisito de tempo real e apresentam soluções assíncronas, nas quais os músicos ouvem os áudios deliberadamente atrasados produzidos por seus companheiros, porém, de acordo com os batimentos sincronizados de um metrônomo.

No entanto, tais abordagens não abrangem casos onde músicos residem entre grandes distâncias ou não é possível ter acesso a conexões dedicadas e \textit{hardwares} de alto valor financeiro, de forma a ainda oferecer uma plataforma de performance colaborativa em tempo real.

Ao observar o contexto de videogames, encontramos requisitos de latência similares. Gêneros que utilizam reações como mecânica de jogabilidade, como luta e FPS (\textit{first-person shooter}), para oferecerem aos jogadores uma experiência fluida, necessitam de latências máximas de até 100 ms \cite{pubnub}. O algoritmo mais popular e efetivo para solucionar esse problema, \textit{client-side prediction} \cite{client-side-prediction}, baseia-se em prever os próximos \textit{inputs} imediatos dos jogadores e agindo antes mesmo que os dados de seu oponente sejam transmitidos; dessa forma, removendo a necessidade inicial de espera. Uma vez que os \textit{inputs} são recebidos, estes são comparados com a previsão realizada e, caso sejam incongruentes entre si, o jogo é retornado ao estado anterior do momento da previsão inicial.

Por possuir requisitos semelhantes de baixa latência, a mesma implementação baseada em previsões tem o potencial de resolver o problema descrito anteriormente para ambientes musicais colaborativos \textit{online}. Caso seja possível prever os próximos sinais digitais produzidos pelos artistas remotos, não haveria necessidade de espera e, portanto, a latência de rede tornaria-se irrelevante.

Evidentemente, as diferenças entre os contextos de \textit{videogames} e práticas musicais não são negligenciáveis. Ao contrário dos jogos, por apresentar uma linearidade no tempo, não é possível retornar ao último momento da música anterior à previsão imediata sem prejudicar a experiência dos artistas. Além disso, a natureza discreta dos \textit{inputs} dos \textit{videogames} e a quantidade bruta de dados produzida é ínfima em comparação a áudios digitais - estima-se que os jogadores profissionais de \textit{Super Smash Bros. Melee} mais técnicos produzem em média 6 \textit{inputs} por segundo \cite{melee_inputs_per_second}; uma transmissão de áudio com \textit{sample rate} de 44,1 kHz produz, por definição, 44.100 diferentes valores no mesmo espaço de tempo \cite{jukebox_dimension}. Portanto, a aplicação do algoritmo de \textit{client-side prediction} para transmissão de música \textit{online} não é trivial, e a necessidade que o modelo preditivo seja o mais acurado possível é ainda mais importante.

Dois ciclos de estudos foram realizados para explorar essa abordagem. No primeiro ciclo, foram utilizados métodos de aprendizagem de máquina da biblioteca Keras \cite{keras}, especificamente LSTM (\textit{Long Short-Term Memory})\cite{lstm}. Modelos foram construídos e treinados com cortes de arquivos de áudio, reproduzindo trechos de músicas tocados por um único instrumento. A partir desses modelos, novas previsões de sequência foram geradas.

O segundo ciclo seguiu uma abordagem de criar um banco de dados de referência e, para cada nova entrada, identificou-se o corte mais semelhante. A semelhança foi calculada a partir um algoritmo de identificação baseado em DTW (\textit{Dynamic Time Warping})\cite{dtw}, implementado pela biblioteca Librosa \cite{librosa}. Possuindo uma janela de referência identificada, a próxima sequência a ela foi assim escolhida como predição da continuidade da música.

Para avaliar os dois modelos, utilizamos dois critérios de sucesso: (1) quão corretas foram as previsões realizadas e; (2) o tempo necessário para gerar as previsões. Dados esses parâmetros, o modelo gerador com LSTM não teve boa performance, falhando nos dois critérios. Entretanto, o modelo indexador com DTW mostrou-se bastante promissor, tendo sucesso nas duas medidas. Em particular para músicos que performam a trilha de base das músicas, com menos improvisos, esse método pode ser explorado futuramente em ambientes reais.

No \chapref{chap:context}, contextualizamos o problema enfrentado pelos ambientes musicais colaborativos \textit{online} atualmente, explorando as atuais abordagens utilizadas que procuram solucioná-lo. No \chapref{chap:solution_propositon}, detalhamos nossa solução proposta - uma adaptação da técnica \textit{client-side prediction} para os ambientes musicais - entrando também em detalhes sobre os dois modelos preditivos experimentados - o modelo gerador de novas sequências (LSTM) e o identificador e indexador de sequências (DTW). No \chapref{chap:lstm} e \chapref{chap:dtw}, exploramos o primeiro e segundo ciclo de estudos respectivamente, onde simulamos um ambiente virtual para testar os modelos preditivos propostos. Finalmente, no \chapref{chap:conclusion}, realizamos uma análise crítica dos resultados apresentados em nossos experimentos, apontando, também, possíveis trabalhos futuros para aprimorá-los.
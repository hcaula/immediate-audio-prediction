\section{Trabalhos futuros}
\label{sec:later_work}

Para o modelo gerador de novas sequências, trazemos nessa Sessão métodos que podem aumentar a corretude das previsões. Já para o modelo indexador, exemplificamos como realizar novos experimentos que melhor simulem um ambiente real colaborativo, de forma a torná-lo viável.

\subsection{Modelo gerador}

\textit{Seq2Seq} é um \textit{framework} codificador/decodificador de propósito geral para o \textit{Tensorflow} \cite{seq2seq}. É utilizado em aplicações que requerem traduções de uma sequências para outras de diferentes domínios. É bastante utilizado em traduções para diferentes idiomas, legendas automáticas de imagens, sumário de textos, entre outros.

Para aplicação em \textit{Time Series Forecasting}, o \textit{seq2seq} considera dois domínios: passado e futuro. Dessa forma, o conjunto de dados constituiria de pares de sequências - o primeiro elemento representando a sequência de áudio tocado e o segundo o que foi reproduzido logo em seguida.

No entanto, é possível melhorar os dados de entrada, mesmo que para o uso do LSTM. Em nossos experimentos, utilizamos os sinais digitais diretamente como entrada para aprendizagem e predição do modelo. Tal abordagem pode não ter sido a ideal, uma vez que é difícil extrair informações desses valores em sua forma básica. Além disso, a dimensionalidade e o volume desses dados é bastante grande, dificultando a aprendizagem.

Recomenda-se, portanto, que haja uma extração de informações antes de usar os dados para aprendizagem nas redes neurais. Por exemplo, extração de \textit{features} como o espectrograma e informações de BPM podem ser utilizadas para concentrar as informações dos dados para aprendizagem.

O Jukebox, mencionado na \subsecref{subsec:new_sequence_generator} como possível método para gerar previsões, enfrenta problemas semelhantes de dimensionalidade. Sua implementação utiliza a rica técnica de compressão VQ-VAE \cite{vq-vae} para reduzir a dimensão dos dados de áudio, facilitando seu processamento. Portanto, seu uso é bastante pertinente em uma adaptação do \textit{client-side prediction}.

\subsection{Modelo indexador}

Há duas principais melhorias para esse modelo: (1) aumentar a base de dados para torná-la mais generalista e; (2) reduzir a janela de áudio de identificação.

Em nosso experimentos, como a base de dados de referência foi reduzida, foi viável realizar a separação das janelas manualmente. No entanto, em uma aplicação real, tal tarefa teria que ser automatizada. Portanto, sugere-se que, para atingir o primeiro objetivo, encontre-se métodos que identifiquem sessões repetidas na música e automaticamente as indexe no conjunto de dados de referência.

Além disso, a medida em que a base de referência cresce, mais tempo o DTW levará para identificar as subsequências, dado que sua complexidade está na ordem de $O(N^2)$. Dessa forma, é importante que a base seja pré-processada, de forma a reduzir a base de dados a cada divisão, como uma espécie de \textit{hash table}. Por exemplo, pode-se separar essas divisões de acordo com a nota principal daquela janela de áudio.